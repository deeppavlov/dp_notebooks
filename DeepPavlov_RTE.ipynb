{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DeepPavlov Library\n",
        "\n",
        "Deeppavlov is a publicly released open-source framework for developing conversational Natural Language Processing models.  DeepPavlov is created for modular and configuration-driven development of NLP models and it is based on PyTorch and supports HuggingFace `transformers`.\n",
        "\n",
        "Useful links:\n",
        "\n",
        "```\n",
        "# Выбран кодовый формат\n",
        "```\n",
        "\n",
        "\n",
        "- `deeppavlov` library documentation: http://docs.deeppavlov.ai/en/master/\n",
        "- `deeppavlov` demo: https://demo.deeppavlov.ai/"
      ],
      "metadata": {
        "id": "rEHOpxtZPHhs"
      },
      "id": "rEHOpxtZPHhs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the library"
      ],
      "metadata": {
        "id": "kKXdYe2dOYFo"
      },
      "id": "kKXdYe2dOYFo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27c1d209-6d26-49b9-a2a9-6a69b4ed4445",
      "metadata": {
        "id": "27c1d209-6d26-49b9-a2a9-6a69b4ed4445"
      },
      "outputs": [],
      "source": [
        "!pip install deeppavlov -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration files"
      ],
      "metadata": {
        "id": "92UGXHldUQy-"
      },
      "id": "92UGXHldUQy-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The DeepPavlov models are defined in the corresponding configuration files (see the full list in docs or on Github).\n",
        "\n",
        "In this notebook we will be working with the `topics_distilbert_base_uncased` model, its configuration file can be found by the [link](https://github.com/deeppavlov/DeepPavlov/blob/master/deeppavlov/configs/classifiers/topics_distilbert_base_uncased.json) . \n",
        " \n",
        "This model is a distilBERT-based classifier trained on a dataset of conversational topics. Let's inspect how a typical configuration file looks like.   \n",
        "\n",
        "Each configuration file consists of five main sections: `dataset_reader`,  `dataset_iterator`, `chainer`, `train`, and `metadata`.\n",
        "\n"
      ],
      "metadata": {
        "id": "erq-ld-DPSUv"
      },
      "id": "erq-ld-DPSUv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `dataset_reader` and `dataset_iterator` are responsible for **accessing the data** and **splitting it** into training, validation, and test sets. `dataset_reader` supports the datasets from HuggingFace. Here we define the path to the dataset folder and the names of the files for each of the data split and use a basic iterator to iterate over the examples while training and infering.\n",
        "\n",
        "```\n",
        "\"dataset_reader\": {\n",
        "    \"class_name\": \"basic_classification_reader\",\n",
        "    \"class_sep\": \";\",\n",
        "    \"x\": \"text\",\n",
        "    \"y\": \"topic\",\n",
        "    \"data_path\": \"{DOWNLOADS_PATH}/dp_topics_downsampled_data/\",\n",
        "    \"train\" : \"train.csv\",\n",
        "    \"valid\" : \"valid.csv\"  \n",
        "  },\n",
        "  \"dataset_iterator\": {\n",
        "    \"class_name\": \"basic_classification_iterator\",\n",
        "    \"seed\": 42\n",
        "```\n",
        "\n",
        "- `chainer` is a **core concept** of DeepPavlov: it **builds a pipeline** from heterogeneous components (Rule-Based/ML/DL) and allows for training or infering of the entire pipeline as a unified unit. `chainer` also specifies component inputs (`in`, `in_y`) and outputs (`out`) as arrays of names.\n",
        "A pipeline element can be either a function or an object of a class that **implements `__call__` method**. Any configuration file can be used within another configuration file as an element of the `chainer`, and any field of the nested configuration file can be overwritten.\n",
        "\n",
        "In this model´s pipeline we first preprocess the data with the Transformer and get BERT embeddings for our examples\n",
        "\n",
        "```\n",
        "\"chainer\": {\n",
        "    \"in\": [\"x\"],\n",
        "    \"in_y\": [\"y\"],\n",
        "    \"pipe\": [\n",
        "      {\n",
        "        \"class_name\": \"torch_transformers_preprocessor\",\n",
        "        \"vocab_file\": \"{TRANSFORMER}\",\n",
        "        \"do_lower_case\": true,\n",
        "        \"max_seq_length\": 128,\n",
        "        \"in\": [\"x\"],\n",
        "        \"out\": [\"bert_features\"]\n",
        "      },\n",
        "```\n",
        "We also create the vocabulary of our target class labels and encode them into one-hot vectors \n",
        "```\n",
        "      {\n",
        "        \"id\": \"classes_vocab\",\n",
        "        \"class_name\": \"simple_vocab\",\n",
        "        \"fit_on\": [\"y\"],\n",
        "        \"save_path\": \"{MODEL_PATH}/classes.dict\",\n",
        "        \"load_path\": \"{MODEL_PATH}/classes.dict\",\n",
        "        \"in\": [\"y\"],\n",
        "        \"out\": [\"y_ids\"]\n",
        "      },\n",
        "      {\n",
        "        \"in\": [\"y_ids\"],\n",
        "        \"out\": [\"y_onehot\"],\n",
        "        \"class_name\": \"one_hotter\",\n",
        "        \"id\": \"my_one_hotter\",\n",
        "        \"depth\": \"#classes_vocab.len\",\n",
        "        \"single_vector\": true\n",
        "      },\n",
        "  ```\n",
        "  We pass our vectors to the classifier.\n",
        "  ```\n",
        "      {\n",
        "        \"class_name\": \"torch_transformers_classifier\",\n",
        "        \"one_hot_labels\": true,\n",
        "        \"n_classes\": \"#classes_vocab.len\",\n",
        "        \"return_probas\": true,\n",
        "        \"pretrained_bert\": \"{TRANSFORMER}\",\n",
        "        \"save_path\": \"{MODEL_PATH}/model\",\n",
        "        \"load_path\": \"{MODEL_PATH}/model\",\n",
        "        \"multilabel\": true,\n",
        "        \"optimizer\": \"AdamW\",\n",
        "        \"optimizer_parameters\": {\"lr\": 1e-05},\n",
        "        \"learning_rate_drop_patience\": 5,\n",
        "        \"learning_rate_drop_div\": 2.0,\n",
        "        \"in\": [\"bert_features\"],\n",
        "        \"in_y\": [\"y_onehot\"],\n",
        "        \"out\": [\"y_pred_probas\"]\n",
        "      },\n",
        "\n",
        "```\n",
        "And we decode the predicted probabilities to labels.\n",
        "```\n",
        "      {\n",
        "        \"in\": \"y_pred_probas\",\n",
        "        \"out\": \"y_pred_ids\",\n",
        "        \"class_name\": \"proba2labels\",\n",
        "        \"max_proba\": false,\n",
        "        \"confidence_threshold\": 0.5\n",
        "      },\n",
        "      {\n",
        "        \"in\": \"y_pred_ids\",\n",
        "        \"out\": \"y_pred_labels\",\n",
        "        \"ref\": \"classes_vocab\"\n",
        "      },\n",
        "      {\n",
        "        \"ref\": \"my_one_hotter\",\n",
        "        \"in\": \"y_pred_ids\",\n",
        "        \"out\": \"y_pred_onehot\"\n",
        "      }\n",
        "    ],\n",
        "    \"out\": [\"y_pred_labels\"]\n",
        "  },\n",
        "```\n",
        "\n",
        "- the `train` section defines **training parameters**, such as trainer class, evaluation metrics, batch size, etc\n",
        "\n",
        "We define all these parameters in this config as well, and also define `validation_patience` which means that training is stopped if the validation metrics are not improved for 10 times in a row (turn to -1 if yu want to train for all the defined epochs), `val_every_n_epochs` defines how often we do the validation. \n",
        "\n",
        "```\n",
        "  \"train\": {\n",
        "    \"epochs\": 100,\n",
        "    \"batch_size\": 64,\n",
        "    \"metrics\": [\n",
        "      {\n",
        "        \"name\": \"f1_macro\",\n",
        "        \"inputs\": [\n",
        "          \"y_onehot\",\n",
        "          \"y_pred_onehot\"\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"name\": \"f1_weighted\",\n",
        "        \"inputs\": [\n",
        "          \"y_onehot\",\n",
        "          \"y_pred_onehot\"\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"name\": \"accuracy\",\n",
        "        \"inputs\": [\n",
        "          \"y\",\n",
        "          \"y_pred_labels\"\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"name\": \"roc_auc\",\n",
        "        \"inputs\": [\n",
        "          \"y_onehot\",\n",
        "          \"y_pred_probas\"\n",
        "        ]\n",
        "      }\n",
        "    ],\n",
        "    \"validation_patience\": 10,\n",
        "    \"val_every_n_epochs\": 1,\n",
        "    \"log_every_n_epochs\": 1,\n",
        "    \"log_every_n_batches\": 100,\n",
        "    \"show_examples\": false,\n",
        "    \"evaluation_targets\": [\n",
        "      \"train\",\n",
        "      \"valid\",\n",
        "      \"test\"\n",
        "    ],\n",
        "    \"tensorboard_log_dir\": \"{MODEL_PATH}/logs\",\n",
        "    \"class_name\": \"torch_trainer\"\n",
        "  },\n",
        "```\n",
        "\n",
        "- the `metadata` section contains **variables** used in other sections of the configuration file, as well as a list of files required by the `chainer` components. Here we define the backbone transfomer (using the name from HuggingFace), the path to store the model after training or downloading it, and we provide the links to the dataset and the pretrained model (if exists).\n",
        "```\n",
        "\"metadata\": {\n",
        "    \"variables\": {\n",
        "      \"TRANSFORMER\": \"distilbert-base-uncased\",\n",
        "      \"ROOT_PATH\": \"~/.deeppavlov\",\n",
        "      \"DOWNLOADS_PATH\": \"{ROOT_PATH}/downloads\",\n",
        "      \"MODELS_PATH\": \"{ROOT_PATH}/models\",\n",
        "      \"MODEL_PATH\": \"{MODELS_PATH}/classifiers/topic_distilbert_base_v0\"\n",
        "    },\n",
        "    \"download\": [\n",
        "      {\n",
        "        \"url\": \"http://files.deeppavlov.ai/datasets/dp_topics_downsampled_dataset_v0.tar.gz\",\n",
        "        \"subdir\": \"{DOWNLOADS_PATH}\"\n",
        "      },\n",
        "      {\n",
        "        \"url\": \"http://files.deeppavlov.ai/deeppavlov_data/classifiers/topic_distilbert_base_v0.tar.gz\",\n",
        "        \"subdir\": \"{MODELS_PATH}/classifiers\"\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "```"
      ],
      "metadata": {
        "id": "GM2cAFTNUXPg"
      },
      "id": "GM2cAFTNUXPg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Usage"
      ],
      "metadata": {
        "id": "Nsq4hbtNWHZZ"
      },
      "id": "Nsq4hbtNWHZZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two ways to work with deeppavlov's models: through command line interface, and through Python."
      ],
      "metadata": {
        "id": "kNWw3IScSipt"
      },
      "id": "kNWw3IScSipt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Deeppavlov from CLI"
      ],
      "metadata": {
        "id": "asBaClAYI6-I"
      },
      "id": "asBaClAYI6-I"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learn about the available command and their parameters by running"
      ],
      "metadata": {
        "id": "qrdHxC2wxsa0"
      },
      "id": "qrdHxC2wxsa0"
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m deeppavlov -h"
      ],
      "metadata": {
        "id": "UVNQ_GW6xyKE"
      },
      "id": "UVNQ_GW6xyKE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get interactive predictions from the pretrained model, run:"
      ],
      "metadata": {
        "id": "Ir7_VpCtSuNd"
      },
      "id": "Ir7_VpCtSuNd"
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m deeppavlov interact sentiment_sst_conv_bert -d -i"
      ],
      "metadata": {
        "id": "xF9lDACx9TY-"
      },
      "id": "xF9lDACx9TY-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `-d` flag is used to download the pre-trained model along with embeddings and all other files needed to run the model that are defined in the `download` variable of `metadata`.\n",
        "\n",
        "The `-i` flag installs all the packages required for the correct use of the specific model."
      ],
      "metadata": {
        "id": "NY95-PwDXicu"
      },
      "id": "NY95-PwDXicu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following command to evaluate your model:"
      ],
      "metadata": {
        "id": "1YEgMXCDY_bo"
      },
      "id": "1YEgMXCDY_bo"
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m deeppavlov evaluate sentiment_sst_conv_bert -d -i"
      ],
      "metadata": {
        "id": "QfqJFZPFratX"
      },
      "id": "QfqJFZPFratX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Deeppavlov from Python"
      ],
      "metadata": {
        "id": "WQyagrqsI4QC"
      },
      "id": "WQyagrqsI4QC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, the same command can be done through Python. We will be using the same model as in the previous section.\n",
        "\n",
        "Bulid the model using the same config name. `download` and `install` arguments correspond to the `-d` and `-i` flags of the command line."
      ],
      "metadata": {
        "id": "ugeX0lM5Z7ow"
      },
      "id": "ugeX0lM5Z7ow"
    },
    {
      "cell_type": "code",
      "source": [
        "from deeppavlov import build_model\n",
        "\n",
        "topic_classifier = build_model('sentiment_sst_conv_bert', download=True, install=True)"
      ],
      "metadata": {
        "id": "SlANyh15F4zl"
      },
      "id": "SlANyh15F4zl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the pretrained model prediction."
      ],
      "metadata": {
        "id": "HqsbCtrZatVq"
      },
      "id": "HqsbCtrZatVq"
    },
    {
      "cell_type": "code",
      "source": [
        "topic_classifier(['I like Italian cuisine?', 'This movie was actually neither that funny, nor super witty.'])"
      ],
      "metadata": {
        "id": "3RhCUtDTGiHv"
      },
      "id": "3RhCUtDTGiHv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python pipelines \n",
        "\n",
        "Python pipelines have recently been added to the Deeppavlov library as well. Here is how you can build the same model we used previously using the Python classes. Currently this interface only works for inference."
      ],
      "metadata": {
        "id": "mYxE8NFahpte"
      },
      "id": "mYxE8NFahpte"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65a41612-9e22-4e28-b955-2837028e78d7"
      },
      "outputs": [],
      "source": [
        "from deeppavlov import Element, Model\n",
        "from deeppavlov.core.commands.utils import expand_path\n",
        "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
        "from deeppavlov.download import download_resource\n",
        "from deeppavlov.models.classifiers.proba2labels import Proba2Labels\n",
        "from deeppavlov.utils.pip_wrapper.pip_wrapper import install_from_config"
      ],
      "id": "65a41612-9e22-4e28-b955-2837028e78d7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31c5130e-44fc-4956-9dd5-fc2a7ed1f48e"
      },
      "outputs": [],
      "source": [
        "classifiers_path = expand_path('~/.deeppavlov/models/classifiers')\n",
        "model_path = classifiers_path / 'sentiment_sst_bert_torch'\n",
        "transformer_name = 'DeepPavlov/bert-base-cased-conversational'\n",
        "vocab_path = model_path / 'classes.dict'"
      ],
      "id": "31c5130e-44fc-4956-9dd5-fc2a7ed1f48e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64ae25a7-dd5b-42e9-b157-920ee03ea9e3"
      },
      "outputs": [],
      "source": [
        "install_from_config('sentiment_sst_conv_bert')\n",
        "\n",
        "download_resource(\n",
        "    'http://files.deeppavlov.ai/v1/classifiers/sentiment_sst_bert/sentiment_sst_bert_torch.tar.gz',\n",
        "    {classifiers_path}\n",
        ")"
      ],
      "id": "64ae25a7-dd5b-42e9-b157-920ee03ea9e3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "273d7f72-c63c-479f-96c7-4d985268a1b5"
      },
      "outputs": [],
      "source": [
        "from deeppavlov.models.preprocessors.torch_transformers_preprocessor import TorchTransformersPreprocessor\n",
        "from deeppavlov.models.torch_bert.torch_transformers_classifier import TorchTransformersClassifierModel"
      ],
      "id": "273d7f72-c63c-479f-96c7-4d985268a1b5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39abd0dc-7cca-4e37-aa45-36cf1cfd32c3"
      },
      "outputs": [],
      "source": [
        "preprocessor = TorchTransformersPreprocessor(vocab_file=transformer_name, max_seq_length=64)\n",
        "\n",
        "classes_vocab = SimpleVocabulary(load_path=vocab_path, save_path=vocab_path)\n",
        "\n",
        "classifier = TorchTransformersClassifierModel(\n",
        "    n_classes=classes_vocab.len,\n",
        "    return_probas=True,\n",
        "    pretrained_bert=transformer_name,\n",
        "    save_path=model_path / 'model',\n",
        "    optimizer_parameters={'lr': 1e-05}\n",
        ")\n",
        "\n",
        "proba2labels = Proba2Labels(max_proba=True)\n",
        "\n",
        "model = Model(\n",
        "    x=['x'],\n",
        "    out=['y_pred_labels'],\n",
        "    pipe=[\n",
        "        Element(component=preprocessor, x=['x'], out=['bert_features']),\n",
        "        Element(component=classifier, x=['bert_features'], out=['y_pred_probas']),\n",
        "        Element(component=proba2labels, x=['y_pred_probas'], out=['y_pred_ids']),\n",
        "        Element(component=classes_vocab, x=['y_pred_ids'], out=['y_pred_labels'])\n",
        "    ]\n",
        ")"
      ],
      "id": "39abd0dc-7cca-4e37-aa45-36cf1cfd32c3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8975fa79-a3c5-4c70-be09-94417d6e8b78"
      },
      "outputs": [],
      "source": [
        "model(['I like watching Arrival with Amy Adams'])"
      ],
      "id": "8975fa79-a3c5-4c70-be09-94417d6e8b78"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train your custom model"
      ],
      "metadata": {
        "id": "dBrMLjP12CR0"
      },
      "id": "dBrMLjP12CR0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To change the config parameters and train your own model, parse the configuration file and change it the way you need.   "
      ],
      "metadata": {
        "id": "X_uotMNybL6b"
      },
      "id": "X_uotMNybL6b"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/deeppavlov/DeepPavlov/master/deeppavlov/configs/classifiers/sentiment_sst_conv_bert.json"
      ],
      "metadata": {
        "id": "1BybdPWc1Iqp"
      },
      "id": "1BybdPWc1Iqp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's change the transformer to `bert-base-uncased` and reduce the number of training epochs to 2.\n",
        "\n",
        "\n",
        "NB: if you have already used the pretrained model in this session, but now you want to train the model from scratch, check that the folder with the model is empty, or change the `MODEL_PATH` config variable to save it in another directory.  "
      ],
      "metadata": {
        "id": "NINpQ5Tvc1GO"
      },
      "id": "NINpQ5Tvc1GO"
    },
    {
      "cell_type": "code",
      "source": [
        "from deeppavlov.core.common.file import read_json\n",
        "\n",
        "config_json = read_json('sentiment_sst_conv_bert.json')\n",
        "\n",
        "# original backbone transformer \n",
        "print(config_json['metadata']['variables']['TRANSFORMER'])"
      ],
      "metadata": {
        "id": "bBlEmzyl1yO_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ac099c-bef1-4ee5-8b3e-8b75f272eb59"
      },
      "id": "bBlEmzyl1yO_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepPavlov/bert-base-cased-conversational\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_json['metadata']['variables']['TRANSFORMER'] ='bert-base-uncased'\n",
        "config_json['train']['epochs'] = 2\n",
        "config_json['metadata']['variables']['MODEL_PATH'] = 'my_custom_models/sentiment_classifier'"
      ],
      "metadata": {
        "id": "FqIoX7EIJd2V"
      },
      "id": "FqIoX7EIJd2V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parse the config and have a look at it after parsing"
      ],
      "metadata": {
        "id": "JZoiPMlf2QH5"
      },
      "id": "JZoiPMlf2QH5"
    },
    {
      "cell_type": "code",
      "source": [
        "from deeppavlov.core.commands.utils import parse_config\n",
        "\n",
        "model_config = parse_config(config_json)"
      ],
      "metadata": {
        "id": "GTYLZjHa2R4g"
      },
      "id": "GTYLZjHa2R4g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config"
      ],
      "metadata": {
        "id": "oJ1TJvTN3sYm"
      },
      "id": "oJ1TJvTN3sYm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train you model using the parsed config"
      ],
      "metadata": {
        "id": "eBfbVa_aeLAI"
      },
      "id": "eBfbVa_aeLAI"
    },
    {
      "cell_type": "code",
      "source": [
        "from deeppavlov import train_model\n",
        "\n",
        "new_sentiment_classifier = train_model(model_config)"
      ],
      "metadata": {
        "id": "e96zqzc8IHnj"
      },
      "id": "e96zqzc8IHnj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check your model's predictions."
      ],
      "metadata": {
        "id": "cWHeRUxRfDAx"
      },
      "id": "cWHeRUxRfDAx"
    },
    {
      "cell_type": "code",
      "source": [
        "new_sentiment_classifier(['I like Italian cuisine?', 'I like listening rock music'])"
      ],
      "metadata": {
        "id": "dFkHdEhjIHk-"
      },
      "id": "dFkHdEhjIHk-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate your model."
      ],
      "metadata": {
        "id": "ZQR2pjwwfGH4"
      },
      "id": "ZQR2pjwwfGH4"
    },
    {
      "cell_type": "code",
      "source": [
        "from deeppavlov import evaluate_model\n",
        "\n",
        "evaluate_model(model_config, download=False)"
      ],
      "metadata": {
        "id": "-AWKo0BWIHh-"
      },
      "id": "-AWKo0BWIHh-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train your own version of the model from CLI, make all the necessary changes in the configuration file and run: "
      ],
      "metadata": {
        "id": "_ajZskktY4wh"
      },
      "id": "_ajZskktY4wh"
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m deeppavlov train path_to_config.json -i"
      ],
      "metadata": {
        "id": "9-k2QVbuPf4I"
      },
      "execution_count": null,
      "outputs": [],
      "id": "9-k2QVbuPf4I"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment\n",
        "Build and train your own BERT-based classifier for the Recognizing Textual Entailment (RTE) task of the GLUE benchmark using [this config](https://github.com/deeppavlov/DeepPavlov/blob/master/deeppavlov/configs/classifiers/glue/glue_rte_cased_bert_torch.json). Read more about the GLUE benchmark [on their website](https://russiansuperglue.com/).\n",
        "\n",
        "Please follow the instructions and do not delete the cell'**s** output."
      ],
      "metadata": {
        "id": "DEX9hN6FqrCI"
      },
      "id": "DEX9hN6FqrCI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1. Train and measure performance."
      ],
      "metadata": {
        "id": "PKvsD5AexS3w"
      },
      "id": "PKvsD5AexS3w"
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and parse the config\n",
        "\n",
        "rte_classifier_config = ..."
      ],
      "metadata": {
        "id": "DuLe_MZcqspb"
      },
      "id": "DuLe_MZcqspb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train your model, the config doesn't contain the pretrained model\n",
        "\n",
        "from deeppavlov import train_model\n",
        "\n",
        "rte_classifier = train_model(rte_classifier_config)"
      ],
      "metadata": {
        "id": "betGpL_EFlDR"
      },
      "id": "betGpL_EFlDR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interact with the model model\n",
        "\n",
        "rte_classifier([sentence1], [sentence2])"
      ],
      "metadata": {
        "id": "lFMKurwCGRaS"
      },
      "id": "lFMKurwCGRaS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Describe what is the purpose of the model, describe the classes, provide few examples for different classes. Find misclassified samples."
      ],
      "metadata": {
        "id": "1Ft1cFGUzMle"
      },
      "id": "1Ft1cFGUzMle",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate your model\n",
        "\n",
        "from deeppavlov import evaluate_model\n",
        "\n",
        "evaluate_model(rte_classifier_config, download=False, install=False)"
      ],
      "metadata": {
        "id": "ai_W--Xnywhl"
      },
      "id": "ai_W--Xnywhl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2. Improve RTE performance."
      ],
      "metadata": {
        "id": "MT0atG75xY9a"
      },
      "id": "MT0atG75xY9a"
    },
    {
      "cell_type": "code",
      "source": [
        "# Propose as many as possible ways to improve the model's performance. Implement the most promising one, change the config file accordingly, retrain the model and evaluate it.\n",
        "\n",
        "# do not forget to change the path\n",
        "rte_classifier_config['metadata']['variables']['MODEL_PATH'] = 'my_custom_models/rte_improved'\n",
        "###"
      ],
      "metadata": {
        "id": "vqkq8o6m0Q9c"
      },
      "id": "vqkq8o6m0Q9c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain the model\n",
        "\n",
        "from deeppavlov import train_model\n",
        "\n",
        "rte_classifier_improved = train_model(rte_classifier_config)"
      ],
      "metadata": {
        "id": "1p0iz5Eu0b-A"
      },
      "id": "1p0iz5Eu0b-A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the improved model\n",
        "\n",
        "from deeppavlov import evaluate_model\n",
        "\n",
        "evaluate_model(rte_classifier_improved, download=False, install=False)"
      ],
      "metadata": {
        "id": "W1OuDR_x0caN"
      },
      "id": "W1OuDR_x0caN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3. Explain improvements."
      ],
      "metadata": {
        "id": "21B3l_Yexe0u"
      },
      "id": "21B3l_Yexe0u"
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate [config](https://github.com/deeppavlov/DeepPavlov/blob/master/deeppavlov/configs/classifiers/glue/glue_rte_roberta_mnli.json)\n"
      ],
      "metadata": {
        "id": "o3eISlXL0gpf"
      },
      "id": "o3eISlXL0gpf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Describe why performance of the new config is higher than the performance of the source config.\n"
      ],
      "metadata": {
        "id": "bksOIlA83UU4"
      },
      "id": "bksOIlA83UU4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4. Leave feedback about **DeepPavlov** framework.\n",
        "\n",
        "### 1. What did you like about the framework.\n",
        "\n",
        "### 2. What you didn't like about the framework.\n",
        "\n",
        "### 3. How would you improve **DeepPavlov**."
      ],
      "metadata": {
        "id": "MtyLoqssxE0m"
      },
      "id": "MtyLoqssxE0m"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "quisqeFGxO5r"
      },
      "id": "quisqeFGxO5r",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}