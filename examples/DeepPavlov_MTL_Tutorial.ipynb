{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeHC94sJ5LtB"
      },
      "source": [
        "If you have not already installed DeepPavlov, you should run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTmWGZBU5LtG"
      },
      "outputs": [],
      "source": [
        "!pip install deeppavlov>=1.1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk-y97ru5LtH"
      },
      "source": [
        "Multitask models are supported in DeepPavlov starting from the version 1.1.1.\n",
        "\n",
        "We will see what the multitask configs in DeepPavlov look like, on the example of config multitask/multitask_example.json.\n",
        "\n",
        "## Dataset reader\n",
        "\n",
        "As a dataset reader, we use the `multitask_reader` class. This class must have a parameter tasks, which is a dictionary `{task name: parameters for the task}`. The order of the tasks in this dictionary must be exactly the same as in the later stages of the config.\n",
        "Any parameter for any task, if it does not exist in that dictionary, is drawn from another parameter - task_defaults. This parameter contains the default dictionary for any task and this dictionary can also be empty.\n",
        "The dataset_reader, path, train, validation, and test fields must exist for all tasks - either as default fields or as fields that are explicitly given in the dictionary.\n",
        "```\n",
        "{\n",
        "    \"dataset_reader\": {\n",
        "   \t \"class_name\": \"multitask_reader\",\n",
        "   \t \"task_defaults\": {\n",
        "   \t\t \"class_name\": \"huggingface_dataset_reader\",\n",
        "   \t\t \"path\": \"glue\",\n",
        "   \t\t \"train\": \"train\",\n",
        "   \t\t \"valid\": \"validation\",\n",
        "   \t\t \"test\": \"test\"\n",
        "   \t },\n",
        "   \t \"tasks\": {\n",
        "   \t\t \"cola\": {\n",
        "   \t\t\t \"name\": \"cola\"\n",
        "   \t\t },\n",
        "   \t\t \"rte\": {\n",
        "   \t\t\t \"name\": \"rte\"\n",
        "   \t\t },\n",
        "   \t\t \"stsb\": {\n",
        "   \t\t\t \"name\": \"stsb\"\n",
        "   \t\t },\n",
        "   \t\t \"copa\": {\n",
        "   \t\t\t \"path\": \"super_glue\",\n",
        "   \t\t\t \"name\": \"copa\"\n",
        "   \t\t },\n",
        "   \t\t \"conll\": {\n",
        "   \t\t\t \"class_name\": \"conll2003_reader\",\n",
        "   \t\t\t \"use_task_defaults\": false,\n",
        "   \t\t\t \"data_path\": \"{DOWNLOADS_PATH}/conll2003/\",\n",
        "   \t\t\t \"dataset_name\": \"conll2003\",\n",
        "   \t\t\t \"provide_pos\": false\n",
        "   \t\t },\n",
        "   \t\t \"squad\": {\n",
        "   \t\t\t \"class_name\": \"squad_dataset_reader\",\n",
        "   \t\t\t \"dataset\": \"squad\",\n",
        "   \t\t\t \"url\": \"http://files.deeppavlov.ai/datasets/squad-v1.1.tar.gz\",\n",
        "   \t\t\t \"data_path\": \"{DOWNLOADS_PATH}/squad_ru_clean/\"\n",
        "   \t\t }\n",
        "   \t }\n",
        "    },\n",
        "```\n",
        "\n",
        "## Dataset iterator\n",
        "\n",
        "As a dataset iterator, we use the `multitask_iterator` class. In this class, we also pass the dictionary tasks, which contain an iterator class name and parameters(if they are set) for all tasks analogously to the `multitask_reader`.\n",
        "We also set in the same class number of gradient accumulation steps, training epochs, and batch size(these parameters need to be also in the trainer).\n",
        "We also pass into the `multitask_iterator` sampling mode, which defines for every task a probability that the samples will be drawn from its set of samples. We support uniform sampling (the same sampling probability for all tasks), plain sampling(sampling probability is proportional to the sample number), and annealed sampling.\n",
        "\n",
        "```\n",
        "\"dataset_iterator\": {\n",
        "   \t \"class_name\": \"multitask_iterator\",\n",
        "   \t \"num_train_epochs\": \"{NUM_TRAIN_EPOCHS}\",\n",
        "   \t \"gradient_accumulation_steps\": \"{GRADIENT_ACC_STEPS}\",\n",
        "   \t \"seed\": 42,\n",
        "   \t \"task_defaults\": {\n",
        "   \t\t \"class_name\": \"huggingface_dataset_iterator\",\n",
        "   \t\t \"label\": \"label\",\n",
        "   \t\t \"use_label_name\": false,\n",
        "   \t\t \"seed\": 42\n",
        "   \t },\n",
        "   \t \"tasks\": {\n",
        "   \t\t \"cola\": {\n",
        "   \t\t\t \"features\": [\"sentence\"]\n",
        "   \t\t },\n",
        "   \t\t \"rte\": {\n",
        "   \t\t\t \"features\": [\"sentence1\", \"sentence2\"]\n",
        "   \t\t },\n",
        "   \t\t \"stsb\": {\n",
        "   \t\t\t \"features\": [\"sentence1\", \"sentence2\"]\n",
        "   \t\t },\n",
        "   \t\t \"copa\": {\n",
        "   \t\t\t \"features\": [\"contexts\", \"choices\"]\n",
        "   \t\t },\n",
        "   \t\t \"conll\": {\n",
        "   \t\t\t \"class_name\": \"basic_classification_iterator\",\n",
        "   \t\t\t \"seed\": 42,\n",
        "   \t\t\t \"use_task_defaults\": false\n",
        "   \t\t },\n",
        "   \t\t \"squad\": {\n",
        "   \t\t\t \"class_name\": \"squad_iterator\",\n",
        "   \t\t\t \"seed\": 1337,\n",
        "   \t\t\t \"shuffle\": true\n",
        "   \t\t }\n",
        "   \t }\n",
        "    },\n",
        "\n",
        "```\n",
        "## Chainer\n",
        "\n",
        "The chainer utilizes elements for every task separately.\n",
        "\n",
        "However, to streamline the multi-task preprocessing, we have introduced the optional `multitask_pipeline_preprocessor` class. For this class, one should set the vocab_file for the tokenizer and either the default preprocessor class name or the list of preprocessor names(not the ones used in configs, but the ones defined in the library). The user can also set whether to do lowercase and whether to print the first example for the debugging purpose.\n",
        "\n",
        "```\n",
        "\t\"chainer\": {\n",
        "   \t \"in\": [\"x_cola\", \"x_rte\", \"x_stsb\", \"x_copa\", \"x_conll\", \"x_squad\"],\n",
        "   \t \"in_y\": [\"y_cola\", \"y_rte\", \"y_stsb\", \"y_copa\", \"y_conll\", \"y_squad\"],\n",
        "   \t \"pipe\": [{\n",
        "   \t\t\t \"class_name\": \"multitask_input_splitter\",\n",
        "                            \t\"keys_to_extract\": [0,1],\n",
        "   \t\t\t \"in\": [\"x_squad\"],\n",
        "   \t\t\t \"out\": [\"question_raw_squad\", \"context_raw_squad\"]\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"class_name\": \"multitask_input_splitter\",\n",
        "                            \t\"keys_to_extract\": [0,1],\n",
        "   \t\t\t \"in\": [\"y_squad\"],\n",
        "   \t\t\t \"out\": [\"ans_raw_squad\", \"ans_raw_start_squad\"]\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"class_name\": \"torch_squad_transformers_preprocessor\",\n",
        "   \t\t\t \"add_token_type_ids\": true,\n",
        "   \t\t\t \"vocab_file\": \"{BACKBONE}\",\n",
        "   \t\t\t \"do_lower_case\": true,\n",
        "   \t\t\t \"max_seq_length\": 384,\n",
        "   \t\t\t \"in\": [\n",
        "   \t\t\t\t \"question_raw_squad\",\n",
        "   \t\t\t\t \"context_raw_squad\"\n",
        "   \t\t\t ],\n",
        "   \t\t\t \"out\": [\n",
        "   \t\t\t\t \"bert_features_squad\",\n",
        "   \t\t\t\t \"subtokens_squad\",\n",
        "   \t\t\t\t \"split_context_squad\"\n",
        "   \t\t\t ]\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"class_name\": \"squad_bert_mapping\",\n",
        "   \t\t\t \"do_lower_case\": true,\n",
        "   \t\t\t \"in\": [\n",
        "   \t\t\t\t \"split_context_squad\",\n",
        "   \t\t\t\t \"bert_features_squad\",\n",
        "   \t\t\t\t \"subtokens_squad\"\n",
        "   \t\t\t ],\n",
        "   \t\t\t \"out\": [\n",
        "   \t\t\t\t \"subtok2chars_squad\",\n",
        "   \t\t\t\t \"char2subtoks_squad\"\n",
        "   \t\t\t ]\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"class_name\": \"squad_bert_ans_preprocessor\",\n",
        "   \t\t\t \"do_lower_case\": true,\n",
        "   \t\t\t \"in\": [\n",
        "   \t\t\t\t \"ans_raw_squad\",\n",
        "   \t\t\t\t \"ans_raw_start_squad\",\n",
        "   \t\t\t\t \"char2subtoks_squad\"\n",
        "   \t\t\t ],\n",
        "   \t\t\t \"out\": [\n",
        "   \t\t\t\t \"ans_squad\",\n",
        "   \t\t\t\t \"ans_start_squad\",\n",
        "   \t\t\t\t \"ans_end_squad\"\n",
        "   \t\t\t ]\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"class_name\": \"multitask_pipeline_preprocessor\",\n",
        "   \t\t\t \"possible_keys_to_extract\": [0, 1],\n",
        "   \t\t\t \"preprocessors\": [\n",
        "   \t\t\t\t \"TorchTransformersPreprocessor\",\n",
        "   \t\t\t\t \"TorchTransformersPreprocessor\",\n",
        "   \t\t\t\t \"TorchTransformersPreprocessor\",\n",
        "   \t\t\t\t \"TorchTransformersMultiplechoicePreprocessor\",\n",
        "   \t\t\t\t \"TorchTransformersNerPreprocessor\"\n",
        "   \t\t\t ],\n",
        "   \t\t\t \"do_lower_case\": true,\n",
        "   \t\t\t \"n_task\": 5,\n",
        "   \t\t\t \"vocab_file\": \"{BACKBONE}\",\n",
        "   \t\t\t \"max_seq_length\": 200,\n",
        "   \t\t\t \"max_subword_length\": 15,\n",
        "   \t\t\t \"token_masking_prob\": 0.0,\n",
        "   \t\t\t \"return_features\": true,\n",
        "   \t\t\t \"in\": [\"x_cola\", \"x_rte\", \"x_stsb\", \"x_copa\", \"x_conll\"],\n",
        "   \t\t\t \"out\": [\n",
        "   \t\t\t\t \"bert_features_cola\",\n",
        "   \t\t\t\t \"bert_features_rte\",\n",
        "   \t\t\t\t \"bert_features_stsb\",\n",
        "   \t\t\t\t \"bert_features_copa\",\n",
        "   \t\t\t\t \"bert_features_conll\"\n",
        "   \t\t\t ]\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"id\": \"vocab_conll\",\n",
        "   \t\t\t \"class_name\": \"simple_vocab\",\n",
        "   \t\t\t \"unk_token\": [\"O\"],\n",
        "   \t\t\t \"pad_with_zeros\": true,\n",
        "   \t\t\t \"save_path\": \"{MODELS_PATH}/tag.dict\",\n",
        "   \t\t\t \"load_path\": \"{MODELS_PATH}/tag.dict\",\n",
        "   \t\t\t \"fit_on\": [\"y_conll\"],\n",
        "   \t\t\t \"in\": [\"y_conll\"],\n",
        "   \t\t\t \"out\": [\"y_ids_conll\"]\n",
        "   \t\t },\n",
        "```\n",
        "\n",
        "## Multitask transformer\n",
        "\n",
        "As a class for multi-task training, we use the `multitask_transformer` class. The backbone model for multi-task training is defined in this class - it is advisable to make it the same as used for the tokenization in the previous components.\n",
        "In this class, one should give as a `tasks` parameter a dictionary that has exactly the same order of tasks as in the reader, iterator, and `in_x` and `in_y` components in the chainer.\n",
        "For every task, a number of options and the task_type needs to be set.\n",
        "You give `in` ( bert_features, the same order as tasks have) and `in_y` ( y for every task, also the same order) and you obtain probabilities if return_probas=True or labels\n",
        " ids if return_probas=False. ( Apart from the regression task, where always scores are returned(sts-b in config) and ner task, where always label ids for every token are returned(conll in config).\n",
        "\n",
        "```\n",
        "   \t \t{\n",
        "   \t\t\t \"id\": \"multitask_transformer\",\n",
        "   \t\t\t \"class_name\": \"multitask_transformer\",\n",
        "   \t\t\t \"optimizer_parameters\": {\n",
        "   \t\t\t\t \"lr\": 2e-5\n",
        "   \t\t\t },\n",
        "   \t\t\t \"gradient_accumulation_steps\": \"{GRADIENT_ACC_STEPS}\",\n",
        "   \t\t\t \"learning_rate_drop_patience\": 2,\n",
        "   \t\t\t \"learning_rate_drop_div\": 2.0,\n",
        "   \t\t\t \"return_probas\": true,\n",
        "   \t\t\t \"backbone_model\": \"{BACKBONE}\",\n",
        "   \t\t\t \"save_path\": \"{MODEL_PATH}\",\n",
        "   \t\t\t \"load_path\": \"{MODEL_PATH}\",\n",
        "   \t\t\t \"tasks\": {\n",
        "   \t\t\t\t \"cola\": {\n",
        "   \t\t\t\t\t \"type\": \"classification\",\n",
        "   \t\t\t\t\t \"options\": 2\n",
        "   \t\t\t\t },\n",
        "   \t\t\t\t \"rte\": {\n",
        "   \t\t\t\t\t \"type\": \"classification\",\n",
        "   \t\t\t\t\t \"options\": 2\n",
        "   \t\t\t\t },\n",
        "   \t\t\t\t \"stsb\": {\n",
        "   \t\t\t\t\t \"type\": \"regression\",\n",
        "   \t\t\t\t\t \"options\": 1\n",
        "   \t\t\t\t },\n",
        "   \t\t\t\t \"copa\": {\n",
        "   \t\t\t\t\t \"type\": \"multiple_choice\",\n",
        "   \t\t\t\t\t \"options\": 2\n",
        "   \t\t\t\t },\n",
        "   \t\t\t\t \"conll\": {\n",
        "   \t\t\t\t\t \"type\": \"sequence_labeling\",\n",
        "   \t\t\t\t\t \"options\": \"#vocab_conll.len\"\n",
        "   \t\t\t\t },\n",
        "   \t\t\t\t \"squad\":{\"type\":\"question_answering\",\n",
        "   \t\t\t\t \"options\":2}\n",
        "   \t\t\t },\n",
        "   \t\t\t \"in\": [\n",
        "   \t\t\t\t \"bert_features_cola\",\n",
        "   \t\t\t\t \"bert_features_rte\",\n",
        "   \t\t\t\t \"bert_features_stsb\",\n",
        "   \t\t\t\t \"bert_features_copa\",\n",
        "   \t\t\t\t \"bert_features_conll\",\n",
        "   \t\t\t\t \"bert_features_squad\"\n",
        "   \t\t\t ],\n",
        "   \t\t\t \"in_y\": [\"y_cola\", \"y_rte\", \"y_stsb\", \"y_copa\", \"y_ids_conll\", \"ans_squad\"],\n",
        "   \t\t\t \"out\": [\n",
        "   \t\t\t\t \"y_cola_pred_probas\",\n",
        "   \t\t\t\t \"y_rte_pred_probas\",\n",
        "   \t\t\t\t \"y_stsb_pred\",\n",
        "   \t\t\t\t \"y_copa_pred_probas\",\n",
        "   \t\t\t\t \"y_conll_pred_ids\",\n",
        "   \t\t\t\t \"results_squad\"\n",
        "   \t\t\t ]\n",
        "   \t\t },\n",
        "```\n",
        "## Multitask metrics\n",
        "After the multitask_transformer, almost all other components are the same as the single-task setting or as mentioned before…\n",
        "\n",
        "```\n",
        "   \t \t{\n",
        "   \t\t\t \"class_name\": \"multitask_input_splitter\",\n",
        "   \t\t\t \"in\": [\"results_squad\"],\n",
        "                            \t\"keys_to_extract\": [0,1,2,3,4],\n",
        "   \t\t\t \"out\": [\"ans_start_predicted_squad\",\n",
        "   \t\t\t\t \"ans_end_predicted_squad\",\n",
        "   \t\t\t\t \"logits_squad\",\n",
        "   \t\t\t\t \"scores_squad\",\n",
        "   \t\t\t\t \"inds_squad\"\n",
        "   \t\t\t ]\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"class_name\": \"squad_bert_ans_postprocessor\",\n",
        "   \t\t\t \"in\": [\n",
        "   \t\t\t\t \"ans_start_predicted_squad\",\n",
        "   \t\t\t\t \"ans_end_predicted_squad\",\n",
        "   \t\t\t\t \"split_context_squad\",\n",
        "   \t\t\t\t \"subtok2chars_squad\",\n",
        "   \t\t\t\t \"subtokens_squad\",\n",
        "   \t\t\t\t \"inds_squad\"\n",
        "   \t\t\t ],\n",
        "   \t\t\t \"out\": [\n",
        "   \t\t\t\t \"ans_predicted_squad\",\n",
        "   \t\t\t\t \"ans_start_predicted_squad\",\n",
        "   \t\t\t\t \"ans_end_predicted_squad\"\n",
        "   \t\t\t ]\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"in\": [\"y_cola_pred_probas\"],\n",
        "   \t\t\t \"out\": [\"y_cola_pred_ids\"],\n",
        "   \t\t\t \"class_name\": \"proba2labels\",\n",
        "   \t\t\t \"max_proba\": true\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"in\": [\"y_rte_pred_probas\"],\n",
        "   \t\t\t \"out\": [\"y_rte_pred_ids\"],\n",
        "   \t\t\t \"class_name\": \"proba2labels\",\n",
        "   \t\t\t \"max_proba\": true\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"in\": [\"y_copa_pred_probas\"],\n",
        "   \t\t\t \"out\": [\"y_copa_pred_ids\"],\n",
        "   \t\t\t \"class_name\": \"proba2labels\",\n",
        "   \t\t\t \"max_proba\": true\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"in\": [\"y_conll_pred_ids\"],\n",
        "   \t\t\t \"out\": [\"y_conll_pred_labels\"],\n",
        "   \t\t\t \"ref\": \"vocab_conll\"\n",
        "   \t\t }\n",
        "   \t ],\n",
        "   \t \"out\": [\"y_cola_pred_ids\", \"y_rte_pred_ids\", \"y_stsb_pred\", \"y_copa_pred_ids\", \"y_conll_pred_labels\"]\n",
        "    },\n",
        "    \"train\": {\n",
        "   \t \"epochs\": \"{NUM_TRAIN_EPOCHS}\",\n",
        "   \t \"batch_size\": 32,\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "…apart from the metrics multitask_accuracy, multitask_f1_macro and multitask_f1_weighted, that calculate the corresponding metrics(accuracy, f1-macro and f1-weighted) for any task and then average them. As in any DeepPavlov config, the early stopping is performed for the first metric in the metric list.\n",
        "```\n",
        "    \t\"metrics\": [{\n",
        "   \t\t\t \"name\": \"multitask_accuracy\",\n",
        "   \t\t\t \"inputs\": [\"y_rte\", \"y_cola\", \"y_copa\", \"y_rte_pred_ids\", \"y_cola_pred_ids\", \"y_copa_pred_ids\"]\n",
        "   \t\t },\n",
        "```\n",
        "However, one can also calculate the single-task metrics.\n",
        "```\n",
        "   \t \t{\n",
        "   \t\t\t \"name\": \"ner_f1\",\n",
        "   \t\t\t \"inputs\": [\"y_conll\", \"y_conll_pred_labels\"]\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"name\": \"ner_token_f1\",\n",
        "   \t\t\t \"inputs\": [\"y_conll\", \"y_conll_pred_labels\"]\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"name\": \"accuracy\",\n",
        "   \t\t\t \"alias\": \"accuracy_cola\",\n",
        "   \t\t\t \"inputs\": [\"y_cola\", \"y_cola_pred_ids\"]\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"name\": \"accuracy\",\n",
        "   \t\t\t \"alias\": \"accuracy_rte\",\n",
        "   \t\t\t \"inputs\": [\"y_rte\", \"y_rte_pred_ids\"]\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"name\": \"accuracy\",\n",
        "   \t\t\t \"alias\": \"accuracy_copa\",\n",
        "   \t\t\t \"inputs\": [\"y_copa\", \"y_copa_pred_ids\"]\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"name\": \"pearson_correlation\",\n",
        "   \t\t\t \"alias\": \"pearson_stsb\",\n",
        "   \t\t\t \"inputs\": [\"y_stsb\", \"y_stsb_pred\"]\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"name\": \"spearman_correlation\",\n",
        "   \t\t\t \"alias\": \"spearman_stsb\",\n",
        "   \t\t\t \"inputs\": [\"y_stsb\", \"y_stsb_pred\"]\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"name\": \"squad_v1_f1\",\n",
        "   \t\t\t \"inputs\": [\n",
        "   \t\t\t\t \"ans_squad\",\n",
        "   \t\t\t\t \"ans_predicted_squad\"\n",
        "   \t\t\t ]\n",
        "   \t\t },\n",
        "   \t\t {\n",
        "   \t\t\t \"name\": \"squad_v1_em\",\n",
        "   \t\t\t \"inputs\": [\n",
        "   \t\t\t\t \"ans_squad\",\n",
        "   \t\t\t\t \"ans_predicted_squad\"\n",
        "   \t\t\t ]\n",
        "   \t\t }\n",
        "   \t ],\n",
        "   \t \"validation_patience\": 3,\n",
        "   \t \"val_every_n_epochs\": 1,\n",
        "   \t \"log_every_n_epochs\": 1,\n",
        "   \t \"show_examples\": false,\n",
        "   \t \"evaluation_targets\": [\"valid\"],\n",
        "   \t \"class_name\": \"torch_trainer\"\n",
        "    },\n",
        "    \"metadata\": {\n",
        "   \t \"variables\": {\n",
        "   \t\t \"ROOT_PATH\": \"~/.deeppavlov\",\n",
        "   \t\t \"MODELS_PATH\": \"{ROOT_PATH}/models/multitask_example\",\n",
        "   \t\t \"DOWNLOADS_PATH\": \"{ROOT_PATH}/downloads\",\n",
        "   \t\t \"BACKBONE\": \"distilbert-base-uncased\",\n",
        "   \t\t \"MODEL_PATH\": \"{MODELS_PATH}/{BACKBONE}\",\n",
        "   \t\t \"NUM_TRAIN_EPOCHS\": 5,\n",
        "   \t\t \"GRADIENT_ACC_STEPS\": 1\n",
        "   \t },\n",
        "   \t \"download\": [{\n",
        "   \t\t \"url\": \"http://files.deeppavlov.ai/deeppavlov_data/multitask/multitask_example_v2.tar.gz\",\n",
        "   \t\t \"subdir\": \"{MODELS_PATH}\"\n",
        "   \t }]\n",
        "    }\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MTL config inference"
      ],
      "metadata": {
        "id": "GIMNHHb-nTd5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LOrgLOF5LtI"
      },
      "source": [
        "For inferring the multitask config in DeepPavlov, one firstly needs to build the model.\n",
        "If you want to infer our pretrained config, you need to build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCCLyYtb5LtL"
      },
      "outputs": [],
      "source": [
        "from deeppavlov import build_model, configs\n",
        "model = build_model('multitask_example', download=True, install=True)\n",
        "\n",
        "\n",
        "# If you use your config from scratch, it should look like\n",
        "# model = build_model('path/to/your/config.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFEjdg3-5LtM"
      },
      "source": [
        "Then, for inferring the config for N tasks, one needs to define the list of N lists of variables,\n",
        "where every list is the list of examples to the certain task.\n",
        "\n",
        "Mind that the order of lists must be exactly the same as the order of tasks in config.\n",
        "\n",
        "If the same phrase needs to be classified for many tasks, it is cached.\n",
        "That speeds the computation up compared to using different phrases.\n",
        "If one does not hand over arguments for any task, one can just pass an empty list.\n",
        "\n",
        "\n",
        "Here is how one can make the list of x."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Szxs-Qu75LtO"
      },
      "outputs": [],
      "source": [
        "tasks =['cola','rte','stsb','copa','conll']\n",
        "# the same order as config\n",
        "x=dict()\n",
        "for task in tasks:\n",
        "    if task=='rte':  # Sentence pair classification/regression\n",
        "       # Example can be a tuple\n",
        "        x[task]=[('pair 1 phrase 1', 'pair 1 phrase 2'),\n",
        "                 ('pair 2 phrase 1', 'pair 2 phrase 2')]\n",
        "    elif task=='cola': # Single sentence classification/regression\n",
        "       # Example can be a string\n",
        "        x[task]=['phrase1']\n",
        "    elif task=='conll': # NER\n",
        "       # For NER, examples are strings\n",
        "        x[task]=['first second'] # NER\n",
        "    elif task=='stsb': # Single sentence regression.\n",
        "       #Examples for any task can be empty, like in that case\n",
        "        x[task]=[]\n",
        "    elif task=='copa':\n",
        "        x[task]=[('context in pair 1', ['choice 1 in pair 1', 'choice 2 in pair 1']),\n",
        "                          ('context in pair 2', ['choice 1 in pair 2', 'choice 2 in pair 2'])]\n",
        "       # Illustrating multiple choice task\n",
        "\n",
        "    else:\n",
        "        x[task]=['test phrase']\n",
        "list_of_x = [x[task] for task in tasks]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To infer the model, one need to pass the concatenation of list of x and list of y.\n",
        "\n",
        "List of y has the same structure as the list of x, but any list for y can be empty."
      ],
      "metadata": {
        "id": "xXuvzUsR5ZgI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLlGgXQq5LtP"
      },
      "outputs": [],
      "source": [
        "list_of_y = [[] for _ in tasks]\n",
        "args = list_of_x + list_of_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avPFMvwK5LtQ"
      },
      "source": [
        "Then we perform inference as for usual DeepPavlov models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUA-uS2W5LtQ"
      },
      "outputs": [],
      "source": [
        "outputs = model(*args)\n",
        "print(outputs)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}